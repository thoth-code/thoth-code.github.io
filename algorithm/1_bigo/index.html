<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <meta charset="utf-8">
    <title>article | Thoth</title>
    <link rel="stylesheet" href="../../font.css">
    <link rel="stylesheet" href="../../article_style.css">
  </head>
  <body>
    <header>
        <div id="logo"><a href="./index.html">Thoth</a></div>
    </header>
    <nav>
      <h1>빅오, 시간복잡도</h1>
    </nav>
    <main>
      <h2>점근적 실행 시간, 시간복잡도</h2>
      <ol>
        <li><strong>점근적 실행 시간 : 입력값의 갯수가 무한대를 항할 떄 함수의 실행시간 추이</strong></li>
        <li>시간복잡도 : 어떤 알고리즘을 수행할 때 걸리는 시간을 설명하는 계산 복잡도</li>
        <ul>
          <li>어렵게 생각할 거 없다.<strong>점근적 실행 시간이랑 비슷한 개념이다</strong></li>
        </ul>
      </ol>
      <h2><strong>빅 오 : 시간 복잡도를 표현하는 방식</strong></h2>
      <ol>
        <li><strong>O(수식)로 나타내며 저 수식은 입력값의 갯수에 따라 걸리는 시간(연산횟수)을 수식으로 표현한 것</strong>이다</li>
        <ul>
          <li>수식은 실제로 걸리는 시간에 대한 정확한 수식이 아닌 <strong>"적당히 정확한" 수식을 사용</strong>한다</li>
          <li>예를들어 n개의 입력값에 대해 4n^2+2n+7의 시간이 걸린다면 여기서 최고차항 미만의 항들과 최고차항의 계수를 버리면 n^2가 될 것이다. 이 수식을 이용해 이 알고리즘의 시간 복잡도는 O(n^2)이다 라고 말 하는 것 이다</li>
        </ul>
        <li>다음은 대표적인 빅 오의 몇가지 예시이다</li>
        <ul>
          <li>O(상수) : 아무리 입력값이 많아도 일정한 시간이 걸린다. 아주 이상적인 알고리즘이지만 다만 상수가 ㅈㄴ 크다면 별 의미 없다</li>
          <li>O(로그n) : 입력값에 따라서 시간이 변하지만 기울가 완만해지기 때문에 입력값의 갯수가 아무리 커도 시간이 드라마틱하게 변하지 않는다</li>
          <li>O(n) : 입력값에 비례해서 시간이 소모됨 선형시간 알고리즘이라고도 불리며 정렬되지 않은 리스트에서 최대최소를 찾는 알고리즘이 해당됨</li>
          <li>O(n로그n) : 팀소트같은 대부분의 효율 좋은 알고리즘이 여기에 해당됨</li>
          <li>O(n^2) : 버블정렬같은 비효율적인 알고리즘이 해당됨</li>
          <li>O(2^n) : 피보나치수를 재귀로 구하는 알고리즘이 여기 해당된다</li>
          <li>O(n!) : 가장 느린 알고리즘이다</li>
        </ul>
        <li>주의할 점은 빅오에서의 상한과 최악을 혼동하지 말라는 것이다</li>
        <ul>
          <li>최선/평균/최악의 경우의 수는 주어진 입력값이 얼마나 계산하기 간편하게 주어지느냐에 따른 것이다. 각각의 경우의 수는 해당하는 경우의 입력값이 들어왔을 때 정확한 하나의 값으로 나오게 된다</li>
          <li>하지만 상한/평균/하한의 경우는 좀 다르다. 얘네들은 정확한 값이 아니라 대충 뭉뚱그리는 식이라고 생각하면 된다. 즉, <strong>상한의 경우 최악의 경우 몇번의 연산을 한다라는 말이 아니고 어떠한 경우에도 이 정도의 연산횟수는 넘지 않을것이다 라는 뜻</strong>이다</li>
          <li>예를 들면 5개의 입력값이 들어왔을 때 최악의 경우 100번의 연산을 하고, 최선의 경우 50번의 연산을 하고 평균적으로는 75의 연산을 하는 알고리즘이 있다고 하자. 그럼 최선/평균/최악의 경우 각각의 연산횟수가 정확히 나오는 셈이다. 하지만 상한과 하한의 경우 이것을 정확히 계산해서 도출하는 형식이 아닌 아무리 오래걸려도 120회까지는 안걸릴것이다(=상한), 아무리 빨라도 50회의 연산을 할 것이다(=하한) 이런식으로 추정하는 것이다.</li>
          <li>즉, O(n^2)의 경우 n개의 입력값이 들어오면 최악의 경우 n^2번의 연산을 할 것이다 이소리가 아니고 <strong>최선/평균/최선의 경우의 수를 다 고려해 봐도 n^2만큼의 연산을 하지 않을 것이다</strong>이런 뜻이 된다</li>
          <li>참고로 상한을 잡는것이 빅 오이고, 하한이 빅 오메가, 평균을 빅 세타라고 한다.</li>
        </ul>
        <li>보통 상한으로 빅 오를 잡긴 하지만, 분할 상환 분석을 통해서도 빅 오를 잡기도 한다</li>
        <ul>
          <li>최악과 최선의 갭차이가 너무 많이 나면 상한으로 빅 오를 잡았을때 너무 비관적이고 정확하지도 않다. 이래서 나온 방법이 분할 상환 분석이다</li>
          <li>이 갭차이가 많이 나는 예시는 동적 할당에서의 더블링을 볼 수 있다. 크기가 n인 배열에 한번 값을 push할때는 그냥 한번의 연산이면 된다. 그냥 넣으면 되기 때문이다. 하지만 그렇게 값을 계속 넣어주다가 배열이 가득 차면 언젠가는 가득 찰 것이다. 이때 크기를 두배로 늘리자고 한다면, 크기가 두배인 배열을 하나 만들고, 여기에 원래 배열에 있던 값을 하나하나 다 복사해넣고, 원래의 배열을 지워야 할 것이다. 그렇다면 평소에는 한번만 하면 됐던 연산이 갑자기 n번+알파의 연산을 해야 된다. 이때 상한으로 잡고 얘의 시간복잡도는 O(n)이라고 측정한다면 너무 억울할 것이다</li>
          <li>이때 분할 상환 분석으로 측정하면, push한번당 한번의 연산이 아니라 3번정도의 연산을 한다고 가정해 놓고, push에 사용된 한번의 연산은 빼고 2번의 연산은 뭐 어디 저장해놨다고 생각하면 더블링이 발생해도 이 저장해놓은 연산을 사용한다고 생각하면 시간복잡도는 O(3)이 된다(예시일뿐 진짜 시간복잡도가 O(3)이라는건 아니다)</li>
          <li>이렇게 <strong>최악의 경우 소모되는 연산횟수를 일반적인 경우의 연산횟수에 골고루 나눠줘서 최악의 경우 너무 극단적으로 연산횟수가 치솟는것을 상쇄시키자는 분석법이 분할 상환 분석이다</strong></li>
          <li>원래 회계에서의 용어로, 연산횟수를 돈으로 바꿔서 생각하면 한결 더 이해하기 쉬울 것이다</li>
        </ul>
        <li>또 병렬화를 통해서도 알고리즘의 속도를 높일 수 있다</li>
        <ul>
          <li>cpu는 빠르지만 한번에 하나의 일만 하는 코어들을 갖고 있고, gpu는 느리지만 한번에 여러개의 일을 할 수 있는 코어들을 갖고 있다.</li>
          <li>이것을 이용해 한번에 여러 일을 하는 식으로 알고리즘을 실행시키면 실행속도가 더 빨라지기도 하더라</li>
        </ul>
      </ol>
    </main>
    <footer>
      copyright©saltwalks2021
    </footer>
  </body>
</html>
